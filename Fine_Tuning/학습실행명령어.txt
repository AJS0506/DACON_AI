

MODELS

I-BRICKS/Cerebro_BM_solar_v01
neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8
hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8
Qwen/Qwen2-7B-Instruct
MLP-KTLim/llama-3-Korean-Bllossom-8B
meta-llama/Meta-Llama-3.1-8B-Instruct
CohereForAI/aya-23-8B
maywell/EXAONE-3.0-7.8B-Instruct-Llamafied
# 학습


CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -m run.train \
    --model_id meta-llama/Meta-Llama-3.1-8B-Instruct \
    --batch_size 1 \
    --gradient_accumulation_steps 62 \
    --epoch 3 \
    --lr 1e-5 \
    --warmup_steps 20

# 로라 튜닝
CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -m run.train_lora \
    --model_id meta-llama/Meta-Llama-3.1-70B-Instruct \
    --batch_size 1 \
    --gradient_accumulation_steps 62 \
    --epoch 3 \
    --lr 1e-4 \
    --warmup_steps 20


# 추론
python -m run.test \
    --output result.json \
    --model_id MLP-KTLim/llama-3-Korean-Bllossom-8B \
    --device cuda:0


