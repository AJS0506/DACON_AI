{'loss': 0.463, 'grad_norm': 6.71875, 'learning_rate': 4.514755582373588e-06, 'epoch': 0.78}                                                                                     
{'loss': 0.4052, 'grad_norm': 5.53125, 'learning_rate': 4.4950430682005995e-06, 'epoch': 0.79}                                                                                   
{'loss': 0.3852, 'grad_norm': 6.4375, 'learning_rate': 4.47498294439647e-06, 'epoch': 0.81}                                                                                      
{'loss': 0.4718, 'grad_norm': 7.15625, 'learning_rate': 4.454578706170075e-06, 'epoch': 0.82}                                                                                    
{'loss': 0.4788, 'grad_norm': 8.3125, 'learning_rate': 4.433833908687633e-06, 'epoch': 0.83}                                                                                     
{'loss': 0.4872, 'grad_norm': 6.78125, 'learning_rate': 4.412752166453271e-06, 'epoch': 0.84}                                                                                    
{'loss': 0.3982, 'grad_norm': 6.375, 'learning_rate': 4.391337152679241e-06, 'epoch': 0.85}                                                                                      
{'loss': 0.415, 'grad_norm': 8.375, 'learning_rate': 4.369592598645912e-06, 'epoch': 0.86}                                                                                       
{'loss': 0.4198, 'grad_norm': 6.125, 'learning_rate': 4.3475222930516484e-06, 'epoch': 0.87}                                                                                                                       
{'loss': 0.4399, 'grad_norm': 7.0625, 'learning_rate': 4.325130081352675e-06, 'epoch': 0.89}                                                                                                                       
{'loss': 0.3404, 'grad_norm': 8.0625, 'learning_rate': 4.302419865093063e-06, 'epoch': 0.9}                                                                                                                        
{'loss': 0.4616, 'grad_norm': 8.5, 'learning_rate': 4.279395601224928e-06, 'epoch': 0.91}                                                                                                                          
{'loss': 0.3465, 'grad_norm': 6.78125, 'learning_rate': 4.256061301418997e-06, 'epoch': 0.92}                                                                                                                      
{'loss': 0.2946, 'grad_norm': 6.5625, 'learning_rate': 4.232421031365618e-06, 'epoch': 0.93}                                                                                                                       
{'loss': 0.4528, 'grad_norm': 9.625, 'learning_rate': 4.208478910066371e-06, 'epoch': 0.94}                                                                                                                        
{'loss': 0.4116, 'grad_norm': 8.5, 'learning_rate': 4.184239109116393e-06, 'epoch': 0.95}                                                                                                                          
{'loss': 0.3276, 'grad_norm': 12.4375, 'learning_rate': 4.159705851977521e-06, 'epoch': 0.97}                                                                                                                      
{'loss': 0.39, 'grad_norm': 9.1875, 'learning_rate': 4.134883413242421e-06, 'epoch': 0.98}                                                                                                                         
{'loss': 0.4137, 'grad_norm': 9.25, 'learning_rate': 4.109776117889789e-06, 'epoch': 0.99}                                                                                                                         
 33%|███████████████████████████████████████████████████████▋                                                                                                               | 86/258 [7:30:14<15:05:18, 315.81s/it]***** Running Evaluation *****
  Num examples = 487
  Batch size = 1
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
{'eval_loss': 0.3924190104007721, 'eval_runtime': 516.6768, 'eval_samples_per_second': 0.943, 'eval_steps_per_second': 0.943, 'epoch': 0.99}                                                                       
 33%|███████████████████████████████████████████████████████▋                                                                                                               | 86/258 [7:43:48<15:05:18, 315.81s/itSaving model checkpoint to resource/results/checkpoint-86                                                                                                                                                           
Configuration saved in resource/results/checkpoint-86/config.json
Configuration saved in resource/results/checkpoint-86/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at resource/results/checkpoint-86/model.safetensors.index.json.
tokenizer config file saved in resource/results/checkpoint-86/tokenizer_config.json
Special tokens file saved in resource/results/checkpoint-86/special_tokens_map.json
{'loss': 0.3835, 'grad_norm': 14.1875, 'learning_rate': 4.084388340530791e-06, 'epoch': 1.0}                                                                                                                       
{'loss': 0.3799, 'grad_norm': 7.0625, 'learning_rate': 4.058724504646834e-06, 'epoch': 1.01}                                                                                                                       
{'loss': 0.4146, 'grad_norm': 7.59375, 'learning_rate': 4.032789081818843e-06, 'epoch': 1.02}                                                                                                                      
{'loss': 0.3716, 'grad_norm': 6.59375, 'learning_rate': 4.006586590948141e-06, 'epoch': 1.04}                                                                                                                      
{'loss': 0.2865, 'grad_norm': 5.09375, 'learning_rate': 3.980121597469096e-06, 'epoch': 1.05}                                                                                                                      
{'loss': 0.3894, 'grad_norm': 6.4375, 'learning_rate': 3.95339871255365e-06, 'epoch': 1.06}                                                                                                                        
{'loss': 0.3289, 'grad_norm': 6.8125, 'learning_rate': 3.926422592307888e-06, 'epoch': 1.07}                                                                                                                       {'loss': 0.4295, 'grad_norm': 8.875, 'learning_rate': 3.899197936960771e-06, 'epoch': 1.08}                                                                                                                        
{'loss': 0.4297, 'grad_norm': 9.1875, 'learning_rate': 3.8717294900451856e-06, 'epoch': 1.09}                                                                                                                      {'loss': 0.3296, 'grad_norm': 7.46875, 'learning_rate': 3.844022037571444e-06, 'epoch': 1.1}                                                                                                                       {'loss': 0.3412, 'grad_norm': 11.5625, 'learning_rate': 3.81608040719339e-06, 'epoch': 1.12}                                                                                                                       {'loss': 0.3592, 'grad_norm': 9.375, 'learning_rate': 3.78790946736724e-06, 'epoch': 1.13}                                                                                                                         {'loss': 0.267, 'grad_norm': 5.0, 'learning_rate': 3.7595141265033243e-06, 'epoch': 1.14}                                                                                                                          {'loss': 0.2572, 'grad_norm': 6.34375, 'learning_rate': 3.7308993321108557e-06, 'epoch': 1.15}                                                                                                                     {'loss': 0.3143, 'grad_norm': 7.0, 'learning_rate': 3.7020700699358984e-06, 'epoch': 1.16}                                                                                                                         {'loss': 0.3469, 'grad_norm': 12.625, 'learning_rate': 3.673031363092666e-06, 'epoch': 1.17}                                                                                                                       
{'loss': 0.3317, 'grad_norm': 7.375, 'learning_rate': 3.643788271188308e-06, 'epoch': 1.18}                                                                                                                        
{'loss': 0.3668, 'grad_norm': 11.9375, 'learning_rate': 3.6143458894413463e-06, 'epoch': 1.2}                                                                                                                      
 40%|██████████████████████████████████████████████████████████████████▉                                                                                                   | 104/258 [9:13:44<13:33:51, 317.09s/it]

 

Configuration saved in resource/results/checkpoint-86/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at resource/results/checkpoint-86/model.safetensors.index.json.
tokenizer config file saved in resource/results/checkpoint-86/tokenizer_config.json
Special tokens file saved in resource/results/checkpoint-86/special_tokens_map.json
{'loss': 0.3835, 'grad_norm': 14.1875, 'learning_rate': 4.084388340530791e-06, 'epoch': 1.0}                                                                                                                       {'loss': 0.3799, 'grad_norm': 7.0625, 'learning_rate': 4.058724504646834e-06, 'epoch': 1.01}                                                                                                                       
{'loss': 0.4146, 'grad_norm': 7.59375, 'learning_rate': 4.032789081818843e-06, 'epoch': 1.02}                                                                                                                      {'loss': 0.3716, 'grad_norm': 6.59375, 'learning_rate': 4.006586590948141e-06, 'epoch': 1.04}                                                                                                                      
{'loss': 0.2865, 'grad_norm': 5.09375, 'learning_rate': 3.980121597469096e-06, 'epoch': 1.05}                                                                                                                      {'loss': 0.3894, 'grad_norm': 6.4375, 'learning_rate': 3.95339871255365e-06, 'epoch': 1.06}                                                                                                                        
{'loss': 0.3289, 'grad_norm': 6.8125, 'learning_rate': 3.926422592307888e-06, 'epoch': 1.07}                                                                                                                       {'loss': 0.4295, 'grad_norm': 8.875, 'learning_rate': 3.899197936960771e-06, 'epoch': 1.08}                                                                                                                        
{'loss': 0.4297, 'grad_norm': 9.1875, 'learning_rate': 3.8717294900451856e-06, 'epoch': 1.09}                                                                                                                      {'loss': 0.3296, 'grad_norm': 7.46875, 'learning_rate': 3.844022037571444e-06, 'epoch': 1.1}                                                                                                                       
{'loss': 0.3412, 'grad_norm': 11.5625, 'learning_rate': 3.81608040719339e-06, 'epoch': 1.12}                                                                                                                       {'loss': 0.3592, 'grad_norm': 9.375, 'learning_rate': 3.78790946736724e-06, 'epoch': 1.13}                                                                                                                         
{'loss': 0.267, 'grad_norm': 5.0, 'learning_rate': 3.7595141265033243e-06, 'epoch': 1.14}                                                                                                                          {'loss': 0.2572, 'grad_norm': 6.34375, 'learning_rate': 3.7308993321108557e-06, 'epoch': 1.15}                                                                                                                     
{'loss': 0.3143, 'grad_norm': 7.0, 'learning_rate': 3.7020700699358984e-06, 'epoch': 1.16}                                                                                                                         {'loss': 0.3469, 'grad_norm': 12.625, 'learning_rate': 3.673031363092666e-06, 'epoch': 1.17}                                                                                                                       
{'loss': 0.3317, 'grad_norm': 7.375, 'learning_rate': 3.643788271188308e-06, 'epoch': 1.18}                                                                                                                        {'loss': 0.3668, 'grad_norm': 11.9375, 'learning_rate': 3.6143458894413463e-06, 'epoch': 1.2}                                                                                                                      
 40%|██████████████████████████████████████████████████████████████████▉                                                                                                   | 104/258 [9:13:44<13:33:51, 317.09s/it]{'loss': 0.2695, 'grad_norm': 7.0, 'learning_rate': 3.5847093477938955e-06, 'epoch': 1.21}                                                                                                                         
{'loss': 0.2331, 'grad_norm': 11.9375, 'learning_rate': 3.5548838100178444e-06, 'epoch': 1.22}                                                                                                                     {'loss': 0.3065, 'grad_norm': 7.09375, 'learning_rate': 3.5248744728151346e-06, 'epoch': 1.23}                                                                                                                     
{'loss': 0.2271, 'grad_norm': 6.625, 'learning_rate': 3.4946865649123025e-06, 'epoch': 1.24}                                                                                                                       {'loss': 0.2629, 'grad_norm': 6.84375, 'learning_rate': 3.464325346149449e-06, 'epoch': 1.25}                                                                                                                      
{'loss': 0.2908, 'grad_norm': 5.90625, 'learning_rate': 3.4337961065637793e-06, 'epoch': 1.27}                                                                                                                     {'loss': 0.3402, 'grad_norm': 7.6875, 'learning_rate': 3.403104165467883e-06, 'epoch': 1.28}                                                                                                                       
{'loss': 0.2817, 'grad_norm': 6.53125, 'learning_rate': 3.3722548705229173e-06, 'epoch': 1.29}                                                                                                                     {'loss': 0.3196, 'grad_norm': 8.4375, 'learning_rate': 3.3412535968068483e-06, 'epoch': 1.3}                                                                                                                       
{'loss': 0.3119, 'grad_norm': 11.125, 'learning_rate': 3.310105745877915e-06, 'epoch': 1.31}                                                                                                                       {'loss': 0.279, 'grad_norm': 6.21875, 'learning_rate': 3.278816744833479e-06, 'epoch': 1.32}                                                                                                                       
{'loss': 0.2466, 'grad_norm': 6.125, 'learning_rate': 3.247392045364426e-06, 'epoch': 1.33}                                                                                                                        {'loss': 0.2678, 'grad_norm': 9.5, 'learning_rate': 3.2158371228052822e-06, 'epoch': 1.35}                                                                                                                         
{'loss': 0.3226, 'grad_norm': 5.96875, 'learning_rate': 3.184157475180208e-06, 'epoch': 1.36}                                                                                                                      {'loss': 0.2656, 'grad_norm': 9.4375, 'learning_rate': 3.152358622245042e-06, 'epoch': 1.37}                                                                                                                       
{'loss': 0.3028, 'grad_norm': 9.625, 'learning_rate': 3.12044610452556e-06, 'epoch': 1.38}                                                                                                                         {'loss': 0.3517, 'grad_norm': 6.75, 'learning_rate': 3.0884254823521064e-06, 'epoch': 1.39}                                                                                                                        
{'loss': 0.2955, 'grad_norm': 6.09375, 'learning_rate': 3.056302334890786e-06, 'epoch': 1.4}                                                                                                                       
{'loss': 0.2224, 'grad_norm': 6.15625, 'learning_rate': 3.024082259171367e-06, 'epoch': 1.41}                                                                                                                      
{'loss': 0.2992, 'grad_norm': 6.65625, 'learning_rate': 2.9917708691120705e-06, 'epoch': 1.43}                                                                                                                     
{'loss': 0.2958, 'grad_norm': 6.53125, 'learning_rate': 2.9593737945414264e-06, 'epoch': 1.44}                                                                                                                     
{'loss': 0.2724, 'grad_norm': 11.125, 'learning_rate': 2.9268966802173437e-06, 'epoch': 1.45}                                                                                                                      
{'loss': 0.2697, 'grad_norm': 8.0625, 'learning_rate': 2.894345184843594e-06, 'epoch': 1.46}                                                                                                                       
{'loss': 0.3646, 'grad_norm': 8.8125, 'learning_rate': 2.8617249800838516e-06, 'epoch': 1.47}                                                                                                                      
{'loss': 0.3218, 'grad_norm': 7.25, 'learning_rate': 2.829041749573484e-06, 'epoch': 1.48}                                                                                                                         
{'loss': 0.2786, 'grad_norm': 8.5, 'learning_rate': 2.7963011879292574e-06, 'epoch': 1.5}                                                                                                                          
{'loss': 0.3596, 'grad_norm': 9.4375, 'learning_rate': 2.7635089997571196e-06, 'epoch': 1.51}                                                                                                                      
{'loss': 0.3327, 'grad_norm': 7.9375, 'learning_rate': 2.730670898658255e-06, 'epoch': 1.52}                                                                                                                       
{'loss': 0.3368, 'grad_norm': 10.6875, 'learning_rate': 2.697792606233562e-06, 'epoch': 1.53}                                                                                                                      
 52%|█████████████████████████████████████████████████████████████████████████████████████                                                                                | 133/258 [11:45:57<11:01:23, 317.47s/it]
[augSFT] 0:python3*                                                                                                                                                                        "super" 21:18 17- 8월-24